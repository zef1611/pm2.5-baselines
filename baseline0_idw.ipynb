{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "outputs": [],
   "metadata": {
    "id": "1a000cee-ae2b-49d6-ba5a-773510c69c52"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics"
   ],
   "outputs": [],
   "metadata": {
    "id": "73118b88-55cb-419b-824e-89a37819b377"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def comp_distance(X1, X2):\n",
    "    \"\"\"\n",
    "    Compute distance of locations in X1 and X2. \n",
    "    Use earth radius R = 6,371 km.\n",
    "    \n",
    "    Args:\n",
    "    X1: lat and lon, shape (m1, 2)\n",
    "    X2: lat and lon, shape (m2, 2)\n",
    "    \n",
    "    Returns:\n",
    "    ouput: distance matrix, shape (m1, m2)\n",
    "    \"\"\"\n",
    "    R = 6371.\n",
    "    X1 = X1 * np.pi/180.\n",
    "    X2 = X2 * np.pi/180.\n",
    "    \n",
    "    A = np.cos(X1[:,[1]]) @ np.cos(X2[:,[1]]).T\n",
    "    A = A * np.cos(X1[:,[0]] - X2[:,[0]].T)\n",
    "    A += np.sin(X1[:,[1]]) @ np.sin(X2[:,[1]]).T\n",
    "    A = np.where(A > 1., 1., A)  # for stability    \n",
    "    \n",
    "    return R * np.arccos(A)\n",
    "\n",
    "\n",
    "def interpolate_pm(\n",
    "        unknown_loc, known_loc, known_pm, num_neighbors):\n",
    "    \"\"\"\n",
    "    Interpolate the PM2.5 values of unknown locations, \n",
    "    using k nearest known stations. \n",
    "    \n",
    "    unkown_pm: array (batch, 1, H, W) if reshape=True,\n",
    "    else shape (batch, num_unknown)\n",
    "    \"\"\"\n",
    "    distance = comp_distance(unknown_loc, known_loc)\n",
    "    distance = np.where(distance < 1e-6, 1e-6, distance)     \n",
    "    bound = np.partition(\n",
    "        distance, num_neighbors - 1, axis=1\n",
    "    )[:, [num_neighbors - 1]]\n",
    "    neighbor_mask = np.where(distance <= bound, 1., np.nan)\n",
    "        \n",
    "    neighbor_dist = distance * neighbor_mask\n",
    "    R = 1 / neighbor_dist\n",
    "    weight = R / np.nansum(R, axis=1, keepdims=True)\n",
    "    weight = np.nan_to_num(weight, nan=0.)\n",
    "    \n",
    "    unknown_pm = known_pm @ weight.T\n",
    "    return unknown_pm\n",
    "\n",
    "\n",
    "def split_dataset(filepath):\n",
    "    \"\"\"\n",
    "    Implement a 60:20:20 contiguous split.\n",
    "    \"\"\"\n",
    "    pm_df = pd.read_csv(\n",
    "        filepath, header=None, skiprows=1)\n",
    "    length = len(pm_df)\n",
    "    train_df = pm_df.loc[: int(0.6 * length)]\n",
    "    valid_df = pm_df.loc[int(0.6 * length): int(0.8 * length)]\n",
    "    test_df = pm_df.loc[int(0.8 * length):]\n",
    "    return train_df, valid_df, test_df\n"
   ],
   "outputs": [],
   "metadata": {
    "id": "f1d45301",
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "data_path = (\"/content/drive/MyDrive/pm2.5/\"\n",
    "            \"data/test_data/long_pm2.5.csv\")\n",
    "loc_path = (\"/content/drive/MyDrive/pm2.5/\"\n",
    "           \"data/test_data/long_locations.csv\")\n",
    "test_mode = True\n",
    "if test_mode:\n",
    "    data_path = \"../data/test_data/long_pm2.5.csv\"\n",
    "    loc_path = \"../data/test_data/long_locations.csv\"\n",
    "\n",
    "# train/target/test indices\n",
    "test_idx = [0,1,4,11,15,24,25,27,32,33,37,39]   \n",
    "train_idx = list(set(range(40)) - set(test_idx))\n",
    "\n",
    "# load dataset\n",
    "loc_df = pd.read_csv(loc_path, header=None, skiprows=1)\n",
    "train_loc = loc_df.iloc[train_idx].to_numpy()\n",
    "test_loc = loc_df.iloc[test_idx].to_numpy()\n",
    "\n",
    "pm_df = pd.read_csv(data_path, header=None, skiprows=1)\n",
    "train_pm = pm_df.iloc[:, train_idx].to_numpy()\n",
    "test_pm = pm_df.iloc[:, test_idx].to_numpy()\n",
    "\n",
    "# compute loss\n",
    "pred_pm = interpolate_pm(\n",
    "    test_loc, train_loc, train_pm, num_neighbors=10)\n",
    "\n",
    "rmse = np.sqrt(metrics.mean_squared_error(pred_pm, test_pm))\n",
    "mae = metrics.mean_absolute_error(pred_pm, test_pm)\n",
    "mape = metrics.mean_absolute_percentage_error(pred_pm, test_pm)\n",
    "\n",
    "print(f'val loss  : {rmse:>.4f} | {mae:>.4f} | {mape:>.4f}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "val loss  : 4.6801 | 3.2924 | 0.3387\n"
     ]
    }
   ],
   "metadata": {
    "id": "ecea6a9a-ca5a-40da-a781-3a04c2753fd0",
    "outputId": "e2ee0975-532a-4ba3-cb74-85cf43a13dd7",
    "tags": []
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "baseline0.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}