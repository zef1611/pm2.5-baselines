{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1a000cee-ae2b-49d6-ba5a-773510c69c52",
    "outputId": "4ecac3ce-e323-472f-cae2-867a5a1f38fc"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import tqdm\n",
    "import copy\n",
    "\n",
    "device = torch.device(\n",
    "    'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    ")"
   ],
   "outputs": [],
   "metadata": {
    "id": "73118b88-55cb-419b-824e-89a37819b377"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Helper functions"
   ],
   "metadata": {
    "id": "eda6b91d"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def haverside_dist(X1, X2):\n",
    "    \"\"\"\n",
    "    Compute haverside (great circle) distance of locations in X1 and X2, use \n",
    "    earth radius R = 6,371 km.\n",
    "    \n",
    "    Args:\n",
    "    X1: lat and lon, shape (m1, 2)\n",
    "    X2: lat and lon, shape (m2, 2)\n",
    "    \n",
    "    Returns:\n",
    "    ouput: distance matrix, shape (m1, m2)\n",
    "    \"\"\"\n",
    "    R = 6371.\n",
    "    X1 = X1 * np.pi/180.\n",
    "    X2 = X2 * np.pi/180.\n",
    "    \n",
    "    A = np.cos(X1[:,[1]]) @ np.cos(X2[:,[1]]).T\n",
    "    A = A * np.cos(X1[:,[0]] - X2[:,[0]].T)\n",
    "    A += np.sin(X1[:,[1]]) @ np.sin(X2[:,[1]]).T\n",
    "    A = np.where(A > 1., 1., A)  # for stability    \n",
    "    \n",
    "    return R * np.arccos(A)\n",
    "\n",
    "\n",
    "def mape_loss(pred, target, reduction='mean'):\n",
    "    \"\"\"\n",
    "    input, output: tensor of same shape\n",
    "    \"\"\"\n",
    "    target = torch.where(\n",
    "        target == 0, \n",
    "        torch.tensor(1e-6, device=device), \n",
    "        target\n",
    "    )\n",
    "    diff = (pred - target) / target\n",
    "    if reduction == 'mean':\n",
    "        mape = diff.abs().mean()\n",
    "    elif reduction == 'sum':\n",
    "        mape = diff.abs().sum()\n",
    "    return mape\n"
   ],
   "outputs": [],
   "metadata": {
    "id": "f070b496-5978-44af-8f4d-e5f2f7aedfc6"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define PM2.5 dataset and dataloader"
   ],
   "metadata": {
    "id": "6dea4036-be3f-4ca3-9daf-aab63fce1737"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def get_params(\n",
    "    loc_df, spatial_res, \n",
    "    temporal_res, num_neighbors\n",
    "):    \n",
    "    \"\"\"\n",
    "    Get parameters of the model.\n",
    "    \n",
    "    h, w: height, width of the network\n",
    "    \"\"\"\n",
    "    x0, y0 = 35., 139.8             \n",
    "    x_max = loc_df.iloc[:, 0].max()  \n",
    "    y_max = loc_df.iloc[:, 1].max()                           \n",
    "    h = int((y_max - y0) // spatial_res + 2)\n",
    "    w = int((x_max - x0) // spatial_res + 2)\n",
    "    \n",
    "    return (spatial_res, temporal_res, \n",
    "            num_neighbors, h, w)\n",
    "\n",
    "\n",
    "def create_network(params):   # verified\n",
    "    \"\"\"\n",
    "    Construct a rectangular virtual station network.\n",
    "    \n",
    "    net_loc: lat & lon, shape (num_stations, 2) \n",
    "    \"\"\"\n",
    "    x0, y0 = 35., 139.8     \n",
    "    spatial_res, _, _, h, w = params\n",
    "    lat = np.arange(x0, x0 + spatial_res * (w - 0.9), spatial_res)\n",
    "    lon = np.arange(y0, y0 + spatial_res * (h - 0.9), spatial_res)\n",
    "    net_loc = np.vstack(\n",
    "        [np.tile(lat, len(lon)), np.repeat(lon, len(lat))]).transpose()\n",
    "    return net_loc\n",
    "\n",
    "\n",
    "def interpolate_pm(\n",
    "    unknown_loc, known_loc, known_pm, params, reshape=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Interpolate the PM2.5 values of unknown locations, using k nearest known stations. \n",
    "    \n",
    "    known_pm: array (batch, num_known)\n",
    "    unkown_pm: array (batch, 1, H, W) if reshape=True, else shape (batch, num_unkown)\n",
    "    \"\"\"\n",
    "    _, _, num_neighbors, h, w = params\n",
    "    distance = haverside_dist(unknown_loc, known_loc)\n",
    "    distance = np.where(distance < 1e-6, 1e-6, distance)     \n",
    "    bound = np.partition(\n",
    "        distance, num_neighbors - 1, axis=1\n",
    "    )[:, [num_neighbors - 1]]\n",
    "    neighbor_mask = np.where(distance <= bound, 1., np.nan)\n",
    "        \n",
    "    neighbor_dist = distance * neighbor_mask\n",
    "    R = 1 / neighbor_dist\n",
    "    weight = R / np.nansum(R, axis=1, keepdims=True)\n",
    "    weight = np.nan_to_num(weight, nan=0.)\n",
    "    \n",
    "    unknown_pm = known_pm @ weight.T\n",
    "    if reshape:\n",
    "        unknown_pm = unknown_pm.reshape([-1, 1, h, w])\n",
    "    return unknown_pm\n",
    "\n",
    "\n",
    "def split_dataset(filepath):\n",
    "    \"\"\"\n",
    "    Implement a 60:20:20 contiguous split.\n",
    "    \"\"\"\n",
    "    pm_df = pd.read_csv(\n",
    "        filepath, header=None, skiprows=1)\n",
    "    length = len(pm_df)\n",
    "    train_df = pm_df.loc[: int(0.6 * length)]\n",
    "    valid_df = pm_df.loc[int(0.6 * length): int(0.8 * length)]\n",
    "    test_df = pm_df.loc[int(0.8 * length):]\n",
    "    return train_df, valid_df, test_df\n",
    "\n",
    "\n",
    "class PMDataset(Dataset):\n",
    "    def __init__(\n",
    "        self, pm_df, loc_df, target_idx, test_idx, \n",
    "        network_loc, params, training=False\n",
    "    ):\n",
    "        \"\"\"\n",
    "        pm_df, loc_df: dataframe\n",
    "        target_idx: integer, test_idx: list\n",
    "        training: False if test dataset\n",
    "        \"\"\"\n",
    "        self.training = training\n",
    "        self.window = params[1]\n",
    "        train_pm, train_loc = self.get_station_data(pm_df, loc_df, train_idx)\n",
    "        self.input_data = torch.tensor(\n",
    "            interpolate_pm(network_loc, train_loc, train_pm, params), \n",
    "            dtype=torch.float32\n",
    "        )\n",
    "        if not self.training:\n",
    "            test_pm, _ = self.get_station_data(pm_df, loc_df, test_idx)\n",
    "            self.target_data = torch.tensor(test_pm, dtype=torch.float32)\n",
    "        else:\n",
    "            target_pm, target_loc = self.get_station_data(\n",
    "                pm_df, loc_df, train_idx + [target_idx])\n",
    "            self.target_data = torch.tensor(\n",
    "                interpolate_pm(network_loc, target_loc, target_pm, params),\n",
    "                dtype=torch.float32\n",
    "            )\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_station_data(pm_df, loc_df, station_idx):\n",
    "        \"\"\"\n",
    "        Retrieve pm2.5 data and locations of given stations.\n",
    "        \"\"\"\n",
    "        station_pm = pm_df.iloc[:, station_idx].to_numpy()\n",
    "        station_loc = loc_df.iloc[station_idx].to_numpy()\n",
    "        return station_pm, station_loc\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.input_data) - self.window + 1\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        input shape: (seq_len, 1, H, W)\n",
    "        target shape: (1, H, W) if testing, else \n",
    "        (num_test,)\n",
    "        \"\"\"\n",
    "        input = self.input_data[idx: idx + self.window]\n",
    "        target = self.target_data[idx + self.window - 1]\n",
    "        return input, target\n"
   ],
   "outputs": [],
   "metadata": {
    "id": "f1d45301",
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define layers & model"
   ],
   "metadata": {
    "id": "2f0c3336-d732-4c3e-bd20-373b7c162557"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "class TimeDistributed(nn.Module):\n",
    "    def __init__(self, layer):\n",
    "        super().__init__()\n",
    "        self.layer = layer\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        input: shape (batch, time, *)\n",
    "        output: shape (batch, time, *)\n",
    "        \"\"\"\n",
    "        output = []\n",
    "        for t in range(input.shape[1]):\n",
    "            output_t = self.layer(input[:, t])\n",
    "            output_t = output_t.unsqueeze(1)\n",
    "            output.append(output_t)\n",
    "        output = torch.cat(output, axis=1)\n",
    "        return output\n",
    "\n",
    "        \n",
    "class tCNN_GRU_Model(nn.Module):\n",
    "    def __init__(self, params):\n",
    "        super().__init__()\n",
    "        self.h, self.w = params[-2:]\n",
    "        self.conv2d = TimeDistributed(nn.Conv2d(1, 8, 3))\n",
    "        self.selu1 = TimeDistributed(nn.SELU())\n",
    "        self.flatten = TimeDistributed(nn.Flatten())\n",
    "        self.gru = nn.GRU(\n",
    "            8*(self.h - 2)*(self.w - 2), 100, 2, \n",
    "            dropout=0.1\n",
    "        )\n",
    "        self.linear = nn.Linear(100, self.h*self.w)\n",
    "        self.selu2 = nn.SELU()\n",
    "    \n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        input: (batch, seq_len, 1, H, W)\n",
    "        output: (batch, 1, H, W)\n",
    "        \"\"\"\n",
    "        conv_out = self.conv2d(input)\n",
    "        conv_out = self.selu1(conv_out)\n",
    "        conv_out = self.flatten(conv_out)\n",
    "        conv_out = torch.swapaxes(conv_out, 0, 1)\n",
    "        gru_out, _ = self.gru(conv_out)\n",
    "        gru_out = gru_out[-1]\n",
    "        lin_out = self.linear(gru_out)\n",
    "        lin_out = self.selu2(lin_out)\n",
    "        output = lin_out.reshape(-1, 1, self.h, self.w)\n",
    "        return output\n",
    "\n",
    "\n",
    "class Predictor(nn.Module):\n",
    "    def __init__(\n",
    "        self, loc_df, test_idx, \n",
    "        net_loc, params\n",
    "    ):\n",
    "        self.test_loc = loc_df.iloc[test_idx].to_numpy()\n",
    "        self.net_loc = net_loc\n",
    "        self.params = params\n",
    "\n",
    "    def __call__(self, net_pm):\n",
    "        \"\"\"\n",
    "        Interpolate test_pm from predicted net_pm.\n",
    "\n",
    "        net_pm: tensor (batch, 1, H, W)\n",
    "        \"\"\"\n",
    "        net_pm = net_pm.cpu().numpy().reshape(net_pm.shape[0], -1)\n",
    "        pred = interpolate_pm(\n",
    "            self.test_loc, self.net_loc, \n",
    "            net_pm, self.params, reshape=False\n",
    "        )\n",
    "        return torch.from_numpy(pred).to(device)\n"
   ],
   "outputs": [],
   "metadata": {
    "id": "f5fee2d2-4915-4f17-ac3d-4f6b69e76b6b"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define training/eval loop"
   ],
   "metadata": {
    "id": "21f662bf-9cfb-45cf-80d2-e0723e149a10",
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def train_loop(model, dataloader, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    total_loss = []\n",
    "    for input, target in dataloader:\n",
    "        # forward pass\n",
    "        input = input.to(device)\n",
    "        target = target.to(device)\n",
    "        pred = model(input)\n",
    "        loss = loss_fn(pred, target)\n",
    "        total_loss.append(loss)\n",
    "    \n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    # print loss\n",
    "    total_loss = torch.tensor(\n",
    "        total_loss).mean().sqrt().item()\n",
    "    print(f'train loss: {total_loss:>.4f}')\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "def eval_loop(model, dataloader, predictor):\n",
    "    mse = mae = mape = 0.\n",
    "    with torch.no_grad():\n",
    "        test_model = copy.deepcopy(model)\n",
    "        test_model.eval()\n",
    "        for input, target in dataloader:\n",
    "            # forward pass\n",
    "            input = input.to(device)\n",
    "            target = target.to(device)\n",
    "            net_pm = test_model(input)\n",
    "            pred = predictor(net_pm)\n",
    "            \n",
    "            # agregate metrics      \n",
    "            mse += F.mse_loss(pred, target, reduction='sum')\n",
    "            mae += F.l1_loss(pred, target, reduction='sum')\n",
    "            mape += mape_loss(pred, target, reduction='sum')\n",
    "\n",
    "    num_entries = len(dataloader.dataset) * len(predictor.test_loc)\n",
    "    rmse = torch.sqrt(mse / num_entries).item()\n",
    "    mae = (mae / num_entries).item()\n",
    "    mape = (mape / num_entries).item()\n",
    "    \n",
    "    print(f'val loss  : {rmse:>.4f} | {mae:>.4f} | {mape:>.4f}')\n",
    "    return rmse, mae, mape\n"
   ],
   "outputs": [],
   "metadata": {
    "id": "77d9bcd1-c284-455a-8e98-1318ad62bccb",
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training time"
   ],
   "metadata": {
    "id": "6e5b404f-3d92-4e8e-a3c0-48b09bc05183"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "data_path = (\"/content/drive/MyDrive/pm2.5/\"\n",
    "            \"data/test_data/(long's)pm2.5.csv\")\n",
    "loc_path = (\"/content/drive/MyDrive/pm2.5/\"\n",
    "           \"data/test_data/(long's)locations.csv\")\n",
    "test_mode = True\n",
    "if test_mode:\n",
    "    data_path = \"../data/test_data/long_pm2.5.csv\"\n",
    "    loc_path = \"../data/test_data/long_locations.csv\"\n",
    "\n",
    "# train/target/test indices\n",
    "target_idx = 14                \n",
    "test_idx = [0,1,4,11,15,24,25,27,32,33,37,39]   \n",
    "train_idx = list(\n",
    "    set(range(40)) - set(test_idx) - set([target_idx]))\n",
    "\n",
    "# hyper-params settings\n",
    "spatial_res = 0.05\n",
    "temporal_res = 5\n",
    "num_neighbors = 10\n",
    "batch_size = 32\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# create net_loc, params\n",
    "loc_df = pd.read_csv(loc_path, header=None, skiprows=1)\n",
    "params = get_params(loc_df, spatial_res, temporal_res, num_neighbors)\n",
    "net_loc = create_network(params)\n",
    "\n",
    "# create dataset & dataloaders\n",
    "train_df, valid_df, test_df = split_dataset(data_path)\n",
    "if test_mode:\n",
    "    train_df = train_df[:100]\n",
    "    valid_df = valid_df[:100]\n",
    "    test_df = test_df[:100]\n",
    "\n",
    "train_dataset = PMDataset(\n",
    "    train_df, loc_df, target_idx, test_idx, \n",
    "    net_loc, params, training=True\n",
    ")\n",
    "valid_dataset = PMDataset(\n",
    "    valid_df, loc_df, target_idx, test_idx, \n",
    "    net_loc, params, training=False\n",
    ")\n",
    "test_dataset = PMDataset(\n",
    "    test_df, loc_df, target_idx, test_idx, \n",
    "    net_loc, params, training=False\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size, shuffle=True)\n",
    "\n",
    "# create training model\n",
    "model = tCNN_GRU_Model(params)\n",
    "model = model.to(device)\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "predictor = Predictor(loc_df, test_idx, net_loc, params)\n",
    "train_loss = []"
   ],
   "outputs": [],
   "metadata": {
    "id": "ecea6a9a-ca5a-40da-a781-3a04c2753fd0",
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "num_epochs = 100\n",
    "for batch in tqdm(range(num_epochs)):\n",
    "    batch_loss = train_loop(\n",
    "        model, train_dataloader, loss_fn, optimizer)\n",
    "    train_loss.append(batch_loss)\n",
    "    if epoch % 10 == 9:\n",
    "        eval_loop(model, valid_dataloader, predictor)\n"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "fb90250df27746ce9196fa9a51f50093",
      "5ab96626459446f98d8d61c47074e01f",
      "09875831720c482e93f0a49518247d30",
      "7d2dde99e6a641548b0212d457644be4",
      "5e6d23c147b746a09089aeea597292e1",
      "2ee41a5ea70f40f891c6f910f5b187bd",
      "b9007f25792345da8b786bae862560a8",
      "9e0ad32eb2684702bcde721870a33d8c"
     ]
    },
    "id": "a6c96b4a-42fd-4606-99a4-ad6bf47304dd",
    "outputId": "13ca5b70-13ce-4b69-8700-081f7aa897ae"
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "baseline1_guo.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "09875831720c482e93f0a49518247d30": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2ee41a5ea70f40f891c6f910f5b187bd",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5e6d23c147b746a09089aeea597292e1",
      "value": 100
     }
    },
    "2ee41a5ea70f40f891c6f910f5b187bd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5ab96626459446f98d8d61c47074e01f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e6d23c147b746a09089aeea597292e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "7d2dde99e6a641548b0212d457644be4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9e0ad32eb2684702bcde721870a33d8c",
      "placeholder": "​",
      "style": "IPY_MODEL_b9007f25792345da8b786bae862560a8",
      "value": " 100/100 [00:50&lt;00:00,  1.97it/s]"
     }
    },
    "9e0ad32eb2684702bcde721870a33d8c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b9007f25792345da8b786bae862560a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fb90250df27746ce9196fa9a51f50093": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_09875831720c482e93f0a49518247d30",
       "IPY_MODEL_7d2dde99e6a641548b0212d457644be4"
      ],
      "layout": "IPY_MODEL_5ab96626459446f98d8d61c47074e01f"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}